{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12a4517",
   "metadata": {},
   "source": [
    "# 0. 라이브러리 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5b4c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFBertForSequenceClassification\n",
    "from transformers import TFTrainer, TFTrainingArguments\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a8e45a",
   "metadata": {},
   "source": [
    "# 1. 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9082ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>풀박승 거의 사용 안 함 액정 본체 전부 깨끗합니다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>주말에 시간씩 영상 시청 용도로 사용했습니다 없이 새것 같습니다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>거의 사용을 안 해서 상태가 매우 좋습니다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>미개봉 새 상품입니다 기가 미개봉 상품입니다 미개봉 상품입니다 기가 미개봉 새 상품...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>최초 실행 배터리 진단 결과 배터리 성능 흠집 찍힘</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>사진 보시면 정말 미개봉인 거 확인 가능하십니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>새 스토어 픽업 미개봉 가격 원 문자 카톡 전화 주세요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>미개봉 애 커플까지 와이프 주려 샀는데 안 한 데서</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>비싼 기기인 만큼 미개봉 그대로 로만 거래할 예정이 궁금하신 거는 언제든지 문자 주세요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>화 도착 예정이 원하시면 배송지 변경으로 보내드립니다 하루라도 빨리 사용하 싶은 분...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  desc  label\n",
       "0                         풀박승 거의 사용 안 함 액정 본체 전부 깨끗합니다      1\n",
       "1                  주말에 시간씩 영상 시청 용도로 사용했습니다 없이 새것 같습니다      1\n",
       "2                              거의 사용을 안 해서 상태가 매우 좋습니다      1\n",
       "3    미개봉 새 상품입니다 기가 미개봉 상품입니다 미개봉 상품입니다 기가 미개봉 새 상품...      0\n",
       "4                         최초 실행 배터리 진단 결과 배터리 성능 흠집 찍힘      1\n",
       "..                                                 ...    ...\n",
       "406                         사진 보시면 정말 미개봉인 거 확인 가능하십니다      0\n",
       "407                     새 스토어 픽업 미개봉 가격 원 문자 카톡 전화 주세요      0\n",
       "408                      미개봉 애 커플까지 와이프 주려 샀는데 안 한 데서       0\n",
       "409   비싼 기기인 만큼 미개봉 그대로 로만 거래할 예정이 궁금하신 거는 언제든지 문자 주세요      0\n",
       "410  화 도착 예정이 원하시면 배송지 변경으로 보내드립니다 하루라도 빨리 사용하 싶은 분...      0\n",
       "\n",
       "[411 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('아이패드 프로 12.9 5세대_크롤링_전처리_ver3.0.csv')\n",
    "data.drop(labels='Unnamed: 0', axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ded0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd220c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:360]\n",
    "test_data = data[360:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b91cf3",
   "metadata": {},
   "source": [
    "# 2. 학습, 검증 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ff30554",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_data['desc'].to_list()\n",
    "train_labels = train_data['label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a24d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=0, stratify=train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03feab61",
   "metadata": {},
   "source": [
    "# 3. 텍스트 토큰화\n",
    "- 토크나이저를 거치면 input_ids, token_type_ids, attetion_mask가 생성됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e21ed881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('kykim/bert-kor-base')\n",
    "\n",
    "# Tokenizing\n",
    "train_encodings = tokenizer(train_texts, return_tensors='pt', truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, return_tensors='pt', truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed870ed2",
   "metadata": {},
   "source": [
    "# 3-1. SMOTE를 활용한 오버 샘플링\n",
    "- 토크나이저에서 나온 input_ids를 train_labels와 함께 오버샘플링\n",
    "- 오버샘플링되어 나온 결과로 다시 새로운 어텐션 마스크 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ffbe69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "train_inputs_over, train_labels_over = smote.fit_resample(train_encodings.input_ids, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca149a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attention_masks = []\n",
    "\n",
    "for seq in train_inputs_over:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    train_attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba6890f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings_over = {\n",
    "    'input_ids': train_inputs_over,\n",
    "    'attention_mask': train_attention_masks,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1856194d",
   "metadata": {},
   "source": [
    "# 4. 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e87c9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset-set\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings_over),\n",
    "    train_labels_over\n",
    "))\n",
    "\n",
    "# validation-set\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2ccfaf",
   "metadata": {},
   "source": [
    "# 5. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b5e5fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained('kykim/bert-kor-base', num_labels=3, from_pt=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6584fc9c",
   "metadata": {},
   "source": [
    "# 6. 콜백 함수 지정 + 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e15689c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:376: FutureWarning: The old compute_loss method is deprecated as it conflicts with the Keras compute_loss method added in TF 2.8. If you want the original HF compute_loss, please call hf_compute_loss() instead. From TF versions >= 2.8, or Transformers versions >= 5, calling compute_loss() will get the Keras method instead.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 213s 7s/step - loss: 0.5767 - accuracy: 0.7978 - val_loss: 0.4199 - val_accuracy: 0.8889\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - 215s 7s/step - loss: 0.2995 - accuracy: 0.9044 - val_loss: 0.4312 - val_accuracy: 0.8750\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - 213s 7s/step - loss: 0.1803 - accuracy: 0.9400 - val_loss: 0.4702 - val_accuracy: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x243341bf5e0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_earlystop = EarlyStopping(\n",
    "    monitor=\"val_loss\", \n",
    "    min_delta=0.001, # the threshold that triggers the termination (acc should at least improve 0.001)\n",
    "    patience=2)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset.shuffle(1000).batch(16), epochs=5, batch_size=16,\n",
    "    validation_data=val_dataset.shuffle(1000).batch(16),\n",
    "    callbacks = [callback_earlystop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850476d1",
   "metadata": {},
   "source": [
    "# 7. 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "832570c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_model\\fine-tuned-kykim-bert-base -- Folder already exists \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('_model\\\\fine-tuned-kykim-bert-base\\\\tokenizer_config.json',\n",
       " '_model\\\\fine-tuned-kykim-bert-base\\\\special_tokens_map.json',\n",
       " '_model\\\\fine-tuned-kykim-bert-base\\\\vocab.txt',\n",
       " '_model\\\\fine-tuned-kykim-bert-base\\\\added_tokens.json')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "MODEL_NAME = 'fine-tuned-kykim-bert-base'\n",
    "MODEL_SAVE_PATH = os.path.join(\"_model\", MODEL_NAME) # change this to your preferred location\n",
    "\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    print(f\"{MODEL_SAVE_PATH} -- Folder already exists \\n\")\n",
    "else:\n",
    "    os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "    print(f\"{MODEL_SAVE_PATH} -- Folder create complete \\n\")\n",
    "\n",
    "# save tokenizer, model\n",
    "model.save_pretrained(MODEL_SAVE_PATH)\n",
    "tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be1082",
   "metadata": {},
   "source": [
    "# 8. 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b42949e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at _model\\fine-tuned-kykim-bert-base were not used when initializing TFBertForSequenceClassification: ['dropout_113']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at _model\\fine-tuned-kykim-bert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "# Load Fine-tuning model\n",
    "loaded_tokenizer = BertTokenizer.from_pretrained(MODEL_SAVE_PATH)\n",
    "loaded_model = TFBertForSequenceClassification.from_pretrained(MODEL_SAVE_PATH, id2label={0: 0 , 1: 1, 2: 2})\n",
    "\n",
    "text_classifier = TextClassificationPipeline(\n",
    "    tokenizer=loaded_tokenizer, \n",
    "    model=loaded_model, \n",
    "    framework='tf',\n",
    "    return_all_scores=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68ebffb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\김철용\\AppData\\Local\\Temp/ipykernel_13280/374369412.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['pred'] = predicted_label_list\n",
      "C:\\Users\\김철용\\AppData\\Local\\Temp/ipykernel_13280/374369412.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['score'] = predicted_score_list\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>서 그 색상 미개봉 합니다</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>올 한 거의 새 상품입니다</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>색상 둘 다 미개봉 신품입니다</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>유심 넣 필요한 앱 몇 개 깔 한 달 출장 다녀와서 거의 만져 보지 않았을 정도네요</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>실 사용이 없어서 급여하려 합니다 배터리 효율입니다</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               desc  label  pred     score\n",
       "360                                  서 그 색상 미개봉 합니다      0     0  0.003629\n",
       "361                                  올 한 거의 새 상품입니다      1     1  0.030661\n",
       "362                                색상 둘 다 미개봉 신품입니다      0     0  0.002230\n",
       "363  유심 넣 필요한 앱 몇 개 깔 한 달 출장 다녀와서 거의 만져 보지 않았을 정도네요      1     1  0.012430\n",
       "364                    실 사용이 없어서 급여하려 합니다 배터리 효율입니다      1     1  0.029144"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label_list = []\n",
    "predicted_score_list = []\n",
    "\n",
    "for text in test_data['desc']:\n",
    "    # predict\n",
    "    preds_list = text_classifier(text)[0]\n",
    "\n",
    "    sorted_preds_list = sorted(preds_list, key=lambda x: x['score'], reverse=True)\n",
    "    predicted_label_list.append(sorted_preds_list[0]['label']) # label\n",
    "    predicted_score_list.append(sorted_preds_list[1]['score']) # score\n",
    "test_data['pred'] = predicted_label_list\n",
    "test_data['score'] = predicted_score_list\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b64c9d9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93        20\n",
      "           1       0.87      0.93      0.90        28\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        51\n",
      "   macro avg       0.59      0.63      0.61        51\n",
      "weighted avg       0.83      0.88      0.86        51\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true=test_data['label'], y_pred=test_data['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975f359d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
